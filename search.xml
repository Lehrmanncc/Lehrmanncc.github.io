<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Love guarantee</title>
    <url>/2020/11/10/Love/</url>
    <content><![CDATA[<p>我曾以为泽泽和恬恬的故事真的就要结束了。那段时间，每当我想起这个结果时，我的心就好疼，因为对于这段感情，我们都付出了所有，爱的很彻底，没有丝毫保留。我想，青春里的爱情最美好的样子也不过如此吧！</p>
<p>那年我18岁，你19岁，一个机缘巧合，我们坐到了一起，开始了真正意义上的熟识吧。那是一个慵懒的下午，来上星期天的晚自习。当我还沉浸在ysc“背叛”我和别人坐的愤怒时，我看了眼，发现旁边是你，那时心里有个感觉：“你会她发生点什么”，我不知道，也没想很多，只是愤怒已经当然无存了。一开始，我们一句话也不说，后来貌似因为我解答了你的问题疑惑而打破僵局，而这时，我与你的故事已经开始。</p>
<p>我加了你QQ，很紧张，那天夜晚，却发现你拒绝了我，一脸懵逼应该是我当时的写照吧，当然最后误会解除了，也是顺利的加上了你，我们开始了日常的聊天，在学校聊不够，回去聊，QQ聊不够，网易云聊。我们聊了真的好多好多，我也是第一次发现，原来我和一个人能这么聊的来，原来你这么有趣，原来我已经深深被你吸引了。</p>
<p>期间发生的一些事情我已经记不起来了，毕竟当时的我们每天就是吃饭，睡觉，做卷子。但我记得，你当时说了一句话，你向ysc说：“你看看lyc，多有耐心，给我讲题”，那天我的心都在飞扬，因为这是被你第一次夸了。我想ysc当时应该笑而不语吧，因为在一个晚上，我曾像他说：我喜欢ppp，他给我说你可能性不是很大，当时算是给我浇了一盆冷水吧。</p>
<p>当我们逐渐熟识后，我们商量着每次小组换座位都坐一起，我还曾想过“入赘”你们组，每次当我想起来，我都忍不住笑，多么美好的事情啊。还记得坐一起的一个晚自习，当时大家在扔粉笔头，jjy向你仍过来一个粉笔头，每次想到这件事情，我总忍不住要拿出来夸耀一番，因为我下意识就用书替你挡住了，一种本能保护你的反应吧。</p>
<p>——2020年11月10日</p>
<hr>
<p>当记忆被打开，往日的思绪就涌了出来。那是个温暖的午后，阳光洒在大地上，我们在这个时间段上起了体育课。与往常一样，解散之后，我去了乒乓球台，打起了乒乓球，只是我貌似观察到了你们在玩跳绳，忘了是谁的邀请，我也加入了你们的跳绳。有很多人，我们玩着跳绳，可惜我跳的并不好，只能在旁边看着，不过xxc貌似看出来我的窘境，于是她开始嚷嚷让你和我一起拉跳绳，紧接着朋友们也跟着吆喝起来，我看见你很羞涩，此处应该说是（少女的羞涩），虽然我也有点不好意思，最后在朋友们的“撮合”下，我们俩一起拉跳绳，几个小朋友也过来跳，我发誓，那是我人生中拉的最紧张的一次跳绳，甚至刚开始都没能摆起绳子。不过在朋友的指导下，我会拉了哈哈哈哈。</p>
<p>每当想起那个画面，我的脑海里充斥了温暖的感觉，绳子的一端是你，我拉着绳子，那根绳子又何尝不是我们俩的一种联系呢，也许在那个时候已经建立起来了。</p>
<p>——2020年11月12日</p>
<hr>
<p>要问我高三最接近你是什么时候，我想也许只有那天了······（未完待续</p>
]]></content>
      <tags>
        <tag>爱情故事</tag>
      </tags>
  </entry>
  <entry>
    <title>Machine learning</title>
    <url>/2020/10/23/ML/</url>
    <content><![CDATA[<h1 id="Regression"><a href="#Regression" class="headerlink" title="Regression"></a><strong>Regression</strong></h1><h2 id="Linear-regression-线性回归"><a href="#Linear-regression-线性回归" class="headerlink" title="Linear regression(线性回归)"></a>Linear regression(线性回归)</h2><h3 id="问题的导入：预测神奇宝贝进化后的战斗力（CP）值"><a href="#问题的导入：预测神奇宝贝进化后的战斗力（CP）值" class="headerlink" title="问题的导入：预测神奇宝贝进化后的战斗力（CP）值"></a>问题的导入：预测神奇宝贝进化后的战斗力（CP）值</h3><ul>
<li><p><strong>输入：进化前神奇宝贝A的CP值，种类，血量（HP），重量（Weight)，高度（Height）</strong></p>
</li>
<li><p><strong>输出：进化后神奇宝贝A的CP值</strong></p>
<p><img src="/2020/10/23/ML/1.png" style="zoom: 67%;"></p>
</li>
</ul>
<h3 id="机器学习的主要步骤："><a href="#机器学习的主要步骤：" class="headerlink" title="机器学习的主要步骤："></a>机器学习的主要步骤：</h3><p><strong>step 1：Model（确定模型）</strong></p>
<p><strong>step 2：Goodless of function（确定损失函数）</strong></p>
<p><strong>step 3：Best function（找到最好的函数）</strong></p>
<h3 id="S-Model"><a href="#S-Model" class="headerlink" title="$\S $Model"></a>$\S $Model</h3><p>在这里，根据常理推测，神奇宝贝进化后的CP值和进化前的CP值有较大的关系，故我们可以假设进化前的CP值与进化后的CP值呈线性关系。</p>
<p>设神奇宝贝进化前的CP值为$x_{cp}$，进化后的CP值为$y$，则可建立以下线性关系：</p>
<script type="math/tex; mode=display">
y=b+wx_{cp} \tag 1</script><p>在这里我们仅考虑了神奇宝贝进化前的CP值这一特征，如果神奇宝贝影响进化后的CP值的不止这一特征，若有n个特征，那么我们可将$x_{cp}$推广到$x_i$，于是便可得到<strong>==Linear model==</strong>（线性模型）：</p>
<script type="math/tex; mode=display">
\begin{cases}
y=b+\sum_i^nw_ix_i\\
x_i:feature\ (特征)\\
w_i:weight \ (权重)\\
b:bias \ (偏差) \\
\end{cases} \tag 2</script><p>在这个模型里，一般而言，我们会有<strong>==training data==</strong>，假设现在我们有10组训练数据，即：</p>
<script type="math/tex; mode=display">
(x^1,\widehat{y}^1)\\
(x^2,\widehat{y}^2)\\
\vdots\\
(x^{10},\widehat{y}^{10}) \tag 3</script><p>对于以上数据来说，它们是已知的，其上标代表了它们的序号，而现在，我们可以将以上数据带入简化模型（式1）中，可得：</p>
<script type="math/tex; mode=display">
\widehat{y}^1=b+wx_{cp}^1\\
\widehat{y}^2=b+wx_{cp}^2\\
\vdots\\
\widehat{y}^{10}=b+wx_{cp}^{10}\\  \tag 4</script><p>对于式4，即就是我们训练数据带入模型后所得，而其只有两个未知数，即$b,w$，而现在我们需要做的就是<strong>找到最适合的$b,w$参数值</strong>。现在就需要损失函数发挥作用了。</p>
<h3 id="S-Goodless-of-function"><a href="#S-Goodless-of-function" class="headerlink" title="$\S $Goodless of  function"></a>$\S $Goodless of  function</h3><ul>
<li><p><strong>损失函数的作用</strong></p>
<script type="math/tex; mode=display">
Loss\ function\ L:
\begin{cases}
input:&\ a\ function\\
output:&\ how\ bad\ it\ is
\end{cases}</script><p>这里要注意评价函数的输入，即为函数$f$，而其输出是它的好坏，但由上式可知，式（4）其<strong>未知量只有待求参数$b,w$，</strong>那么函数评价函数$L(f)$即为：</p>
<script type="math/tex; mode=display">
L(f)=L(w,b) \tag 5</script><p>那么现在，<strong>对于输出所评价函数的好坏即可转化为评价参数$w,b$的好坏。</strong></p>
</li>
<li><p><strong>常见的损失函数</strong></p>
<p>现在我们已有真实数据，那么如何反映其参数的好坏呢，我们可以<strong>通过真实的CP值与预测CP值的差进行衡量</strong>，如下所示：</p>
<script type="math/tex; mode=display">
L(f)=\sum_{i=1}^{10}(\widehat{y}^i-f(x_{cp}^i))^2\Longrightarrow\ L(w,b)=\sum_{i=1}^{10}(\widehat{y}^i-(b+w\cdot x_{cp}^i))^2 \tag 6</script><p>当真实值与误差值较小时，那么此时的$w,b$可认为是最好的，则我们的目标即为：</p>
<script type="math/tex; mode=display">
min\quad L(w,b)</script><p>于是我们现在就需要对其进行求解。</p>
</li>
</ul>
<h3 id="S-Best-function-——-Gradient-Descent（梯度下降法）"><a href="#S-Best-function-——-Gradient-Descent（梯度下降法）" class="headerlink" title="$\S $Best  function ——-Gradient  Descent（梯度下降法）"></a>$\S $Best  function ——-Gradient  Descent（梯度下降法）</h3><p>我们需要通过$Loss\ Function\Longrightarrow”the \ best\ function”$，即达到我们的目标，令：</p>
<script type="math/tex; mode=display">
w*,b*=arg\ \ min_{w,b}\ \ L(w,b)=arg\ \ min_{w,b}\ \ \sum_{i=1}^{10}(\widehat{y}^i-(b+w\cdot x_{cp}^i))^2 \tag 7</script><p>对于以上，我们可以采用穷举法，求得$L(w,b)$的最小值，但下面介绍更加高效的算法。</p>
<ul>
<li><p>==梯度下降法==</p>
<p>若现在损失函数$L(w,b)$只考虑其$w$单变量情况，有以下函数图像：</p>
<p><img src="/2020/10/23/ML/2.png" style="zoom:60%;"></p>
<p>当我们现在<strong>随机</strong>在函数上选择一点$w^0$，</p>
<p>1.如果函数在该点的斜率为负，即导数$\frac{\mathrm{d}L}{\mathrm{d}w}&lt;0$，那么此时函数应该为<strong>递减的</strong>，于是可以考虑增大$w^0$。</p>
<p>2.如果函数在该点的斜率为正，即导数$\frac{\mathrm{d}L}{\mathrm{d}w}&gt;0$，那么此时函数应该为<strong>递增的</strong>，于是可以考虑减少$w^0$。</p>
<p>增大多少或减少多少？</p>
<p>定义每次移动的步长为：</p>
<script type="math/tex; mode=display">
step=\eta\frac{\mathrm{d}L}{\mathrm{d}w}|w=w^0 \tag 8</script><p>在式（8）中，$\eta$称为”learning rate（学习率）”，<strong>我们可以通过控制$\eta$的大小，从而增加step，以此可以提高求解效率，但若$\eta$过大，则会导致步长过大，那么有可能会错过最优解，故我们需要选取合适的$\eta$。而$\frac{\mathrm{d}L}{\mathrm{d}w}|w=w^0$，其微分值越大$\rightarrow$曲线越陡峭$\rightarrow$移动步长越大$\rightarrow$提高求解效率。</strong></p>
<p>以上图为例，其算法如下：</p>
<script type="math/tex; mode=display">
w^0-\eta\frac{\mathrm{d}L}{\mathrm{d}w}|w=w^0\Longrightarrow w^1\\
w^1-\eta\frac{\mathrm{d}L}{\mathrm{d}w}|w=w^1\Longrightarrow w^2\\
\vdots \ \ 更新循环\\
w^{t-1}-\eta\frac{\mathrm{d}L}{\mathrm{d}w}|w=w^{t-1}\Longrightarrow w^t</script><p>在上式中，因为$\frac{\mathrm{d}L}{\mathrm{d}w}|w=w^{0}&lt;0$，故需给其添加负号。对点不断更新循环，直到$(\frac{\mathrm{d}L}{\mathrm{d}w}|w=w^{t})=0$停止，此时$w=w^t$即所求参数的最优解。</p>
<p><strong>但从上图我们可以发现$w^t$其实并不为global optimal solution(全局最优解)，其为local optimal solution(局部最优解)，不过由于我们研究的为线性回归，所以不存在局部最优解。故在线性回归中，梯度下降法是有效的。</strong></p>
<p>现在，我们可以将单变量$w$推广到多变量$w,b$，函数如下图所示：</p>
<p><img src="/2020/10/23/ML/3.png" style="zoom:67%;"></p>
<p>随机选取点$(w^0,b^0)$，计算函数在该点的偏导$\frac{\partial L}{\partial w}|w=w^0,b=b^0,\frac{\partial L}{\partial b}|w=w^0,b=b^0$。</p>
<p>那么函数在该点的梯度即为：</p>
<script type="math/tex; mode=display">
grad\ L(w^0,b^0)=\nabla L(w^0,b^0)=(\frac{\partial L}{\partial w}|w^0,b^0)\overrightarrow{i}+(\frac{\partial L}{\partial b}|w^0,b^0)\overrightarrow{j}\tag 9</script><p>其中$\nabla$为向量微分算子。</p>
<p><strong>而对于梯度向量，其方向为曲线在等值线上的法线方向（高数中有对其的证明），其通过不断的增加步长以更新点，从而达到最优解，如上图所示。</strong></p>
<p>与单变量相同，多变量算法与其相同：</p>
<script type="math/tex; mode=display">
\begin{cases}
w^0-\eta\frac{\partial L}{\partial w}|w=w^0,b=b^0\Longrightarrow w^1\\
b^0-\eta\frac{\partial L}{\partial b}|w=w^0,b=b^0\Longrightarrow b^1
\end{cases}\\
\begin{cases}
w^1-\eta\frac{\partial L}{\partial w}|w=w^1,b=b^1\Longrightarrow w^2\\
b^1-\eta\frac{\partial L}{\partial b}|w=w^1,b=b^1\Longrightarrow b^2
\end{cases}\\
\vdots\ \ 更新循环\\
\begin{cases}
w^t-\eta\frac{\partial L}{\partial w}|w=w^t,b=b^t\Longrightarrow w^t\\
b^t-\eta\frac{\partial L}{\partial b}|w=w^t,b=b^t\Longrightarrow b^t
\end{cases}\\</script><p>最后直到$\nabla L(w^t,b^t)=0$停止，此时<strong>$w^t,b^t$即为所求得的最优解，由于在线性回归中，所以不同担心会由于初始值的选取，而影响达到全局最优解。</strong></p>
</li>
</ul>
<h3 id="S-Result"><a href="#S-Result" class="headerlink" title="$\S $Result"></a>$\S $Result</h3><p>如果现在通过十组训练数据，得到的结果如下图所示：</p>
<p><img src="/2020/10/23/ML/4.png" style="zoom: 67%;"></p>
<p>如图所示，其通过梯度下降法，所求得的最优参数$b,w$分别为-188.4，2.7，其中，损失值可用$\frac{1}{10}\sum_{n=1}^{10}\mathrm{e}^n$表示，<strong>$e^n$即为第n组真实值与预测值的差值。</strong></p>
<p>现在将model改用不同函数，观察其结果变化情况，如下图所示：</p>
<p><img src="/2020/10/23/ML/5.png" style="zoom: 67%;"><br><img src="/2020/10/23/ML/6.png" style="zoom: 67%;"><br><img src="/2020/10/23/ML/7.png" style="zoom: 67%;"><br><img src="/2020/10/23/ML/8.png" style="zoom: 67%;"></p>
<p>可以发现，<strong>随着Model改用函数的阶数的升高，训练集损失值越来越小，但可以发现测试集损失值却并不是越来越少，相反，当阶数大于4后，其测试集损失值增大较多，而这种现象叫做”Overfitting”(过拟合)。</strong></p>
<p>那么我们如何才能防止过拟合的发生呢？</p>
<ul>
<li><p><strong>Regularization(正则化)</strong></p>
<p><strong>由于过拟合是model过度拟合其在训练集的数据，则其会造成曲线波动较大，而如果能让曲线变得smooth平滑，便可防止过拟合。</strong></p>
<p><strong>于是考虑，增加一个与参数$w$（斜率）相关的值，如果loss function 越小的话，那么对应这个值也会越小，即$w$也会越小，于是便会使函数更加平滑。</strong></p>
<p>于是可在线性回归模型中，将loss function变为：</p>
<script type="math/tex; mode=display">
L=\sum_{i=1}^{10}(\widehat{y}^i-(b+\sum_jw_jx_j))^2+\lambda\sum_j(w_j)^2 \tag{10}</script><p>而在式（10）中，$\lambda\sum_j(w_j)^2$称为正则化项，$\lambda$称为正则化参数，它的作用就是平衡loss function这两项，若$\lambda$取得非常大，即对参数$w_j$惩罚的非常大，那么相当于$w_j$趋于0，即相当于原线性回归模型中删除了这些项，那么函数就变成了一条$y=b$的水平直线。</p>
<p>那么为什么减小$w_j$能够使其函数不宜发生overfitting呢？</p>
<p>若现在令$\varDelta x_j$为输入时的干扰项，那么输出所形成的误差即为：</p>
<script type="math/tex; mode=display">
y=b+\sum_jw_j(x_j+\varDelta x_j) \Longrightarrow \varDelta y=w_j\varDelta x_j</script><p>由此我们可以发现，当$w_j$较小时，产生的误差$\varDelta y$也更小，则更加光滑的函数会受更少的影响。</p>
<p>但观察正则化项，我们会发现为什么没有$b$呢？</p>
<p><strong>其实，正则化调整的是函数的平滑程度，但我们调整b对函数的平滑程度不会造成影响，它只能让函数上下移动。</strong></p>
</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenCV 基础操作</title>
    <url>/2020/10/14/opencv/</url>
    <content><![CDATA[<h2 id="图像上的算术运算"><a href="#图像上的算术运算" class="headerlink" title="图像上的算术运算"></a>图像上的算术运算</h2><h3 id="图像融合"><a href="#图像融合" class="headerlink" title="图像融合"></a>图像融合</h3><ul>
<li><p><strong>图像融合即也是图像加法，但它是对每个图像乘以相应的权重，使其具有融合或透明的感觉。根据以下等式进行运算。</strong></p>
<script type="math/tex; mode=display">
G(x)=(1-\alpha)f_1(x)+\alpha f_2(x),\quad \alpha\in[0,1]</script></li>
<li><p><strong>f(x)可作为输入的图像，则上式可变为：</strong></p>
<script type="math/tex; mode=display">
dst=\beta\cdot img_1+\alpha\cdot img_2+\gamma\\
\beta+\alpha=1</script></li>
<li><p><strong>在OpenCV中进行图像融合的函数为cv.addWeighted(img1,$\beta$,img2,$\alpha,\gamma$),其有四个参数,img1与img2分别为输入的图像，$\beta,\alpha$分别为各自图像融合时所占的权重，一般情况下$\gamma$为0。</strong></p>
<p>以下为测试代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span>  cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">img1=cv.imread(<span class="string">r&#x27;D:\Python\image_processing\exercise\save.png&#x27;</span>)</span><br><span class="line">img2=cv.imread(<span class="string">r&#x27;D:\Python\image_processing\exercise\imori.jpg&#x27;</span>)</span><br><span class="line"></span><br><span class="line">dst1=cv.addWeighted(img1,<span class="number">0.8</span>,img2,<span class="number">0.2</span>,<span class="number">0</span>)</span><br><span class="line">dst2=cv.addWeighted(img1,<span class="number">0.2</span>,img2,<span class="number">0.8</span>,<span class="number">0</span>)</span><br><span class="line">images=[dst1,dst2]</span><br><span class="line">titles=[<span class="string">&#x27;dst1&#x27;</span>,<span class="string">&#x27;dst2&#x27;</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    images[i]=cv.cvtColor(images[i],cv.COLOR_BGR2RGB)</span><br><span class="line">    plt.subplot(<span class="number">1</span>,<span class="number">2</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(images[i],<span class="string">&#x27;jet&#x27;</span>)</span><br><span class="line">    plt.title(titles[i],fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.xticks([]),plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>代码解读：</p>
</li>
<li><p>在这里要注意到，使用Matplotlib显示图片时，要先将图片转换为RGB形式，在OpenCV中，图像是以BGR通道存储的，直接显示会出现问题。</p>
</li>
<li><p>上述测试代码里的img1为img2的灰度图，可以发现当$\beta$取0.8，$\alpha$取0.2时，img1融合时占比较高，当$\beta$取0.2，$\alpha$取0.8时，二者的对比结果如下图所示：</p>
<p><img src="/2020/10/14/opencv/4.png" alt="运行结果图" style="zoom:40%;"></p>
<p>可以发现前者更加偏灰度，后者更加偏向原图。</p>
</li>
</ul>
<h3 id="按位运算"><a href="#按位运算" class="headerlink" title="按位运算"></a>按位运算</h3><ul>
<li><p>有时候，我们不想将图像相加或者融合，例如，下面这张图片：</p>
<p><img src="/2020/10/14/opencv/5.png" style="zoom: 25%;"></p>
<p>它就是由两张图片——（西电LOGO和人物图）进行“掩盖”合成的。</p>
</li>
<li><p><strong>按位操作分为以下四种：AND，OR，NOT，XOR，一一介绍它们的运算：</strong></p>
<p><strong>1. AND：即“与”运算，（1&amp;1=1，1&amp;0=0，0&amp;1=0，0&amp;0=0），其具体意义可理解为，只有两值都大于0，其为真。而在像素中，其取值在0~255之间，0为黑色，255为白色，而这里大于0的像素值都可以看作1。在两个都大于0的像素值之间进行AND运算，其结果取较小的像素值！</strong></p>
<p><strong>2. NOT：即“非”运算，（~1=0，~0=1），其具体意义可理解为，取像素的相反值，则当图像为二值图时，原图的黑色变为白色，白色变为黑色。</strong></p>
<p><strong>3. OR：即“与”运算，（1|1=1，1|0=1，0|1=1，0|0=0），其具体意义可理解为，只有当两值都为0，其为假。而对于两像素值，其先进行二进制转换，后对其进行运算，例如3|5：00000011|00000101=00000111，因此3|5=7。</strong></p>
<p><strong>4. XOR：即“异或”运算，（1^1=0，1^0=1，0^1=1，0^0=0），其具体意义可理解为，只有当两值不相同时，其为真。对于两两像素值，先进行二进制转换，后对其进行运算，例如3^5：00000011^00000101=00000110，因此3^5=6。</strong></p>
</li>
<li><p><strong>OpenCV中，进行按位运算的有以下四个函数：cv.bitwise_not，cv.bitwise_and，cv.bitwise_or，cv.bitwise_xor，这四个函数即对应上面的运算规则。下面将以下两张图片合成为上图：</strong></p>
<p><img src="/2020/10/14/opencv/6.jpg" style="zoom:25%;"></p>
<p><img src="/2020/10/14/opencv/7.jpg" style="zoom:25%;"></p>
<p>代码如下:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img1=cv.imread(<span class="string">r&#x27;D:\Python\image_processing\exercise\xidian1.jpg&#x27;</span>)</span><br><span class="line">img2=cv.imread(<span class="string">r&#x27;D:\Python\image_processing\exercise\girl.jpg&#x27;</span>)</span><br><span class="line">row,cols,channels=img1.shape</span><br><span class="line">roi=img2[<span class="number">0</span>:row,<span class="number">0</span>:cols]</span><br><span class="line"></span><br><span class="line">img1_gray=cv.cvtColor(img1,cv.COLOR_BGR2GRAY)</span><br><span class="line">ret,dst1=cv.threshold(img1_gray,<span class="number">200</span>,<span class="number">255</span>,cv.THRESH_BINARY_INV)</span><br><span class="line">dst1_inv=cv.bitwise_not(dst1)</span><br><span class="line"></span><br><span class="line">img2_bg=cv.bitwise_and(roi,roi,mask=dst1_inv)</span><br><span class="line">img1_bg=cv.bitwise_and(img1,img1,mask=dst1)</span><br><span class="line"></span><br><span class="line">dst=cv.add(img1_bg,img2_bg)</span><br><span class="line">img2[<span class="number">0</span>:row,<span class="number">0</span>:cols]=dst</span><br><span class="line"></span><br><span class="line">cv.imshow(<span class="string">&#x27;images&#x27;</span>,img2)</span><br><span class="line"></span><br><span class="line">cv.waitKey(<span class="number">0</span>)</span><br><span class="line">cv.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p>代码解读:</p>
<ul>
<li><p><strong>首先由shape得到img1（LOGO）图像的大小，即行数和列数。由此，可以在img2图像上，通过numpy直接划分出与img1图像一样大小的 roi图像（为原图的左上角）。</strong></p>
</li>
<li><p><strong>通过threshold函数可将img1图像二值化，而在这之前需要将img1图像转换为灰度图，才能将其传入。使用 THRESH_BINARY_INV方法将其二值化，二值化图像如下：</strong></p>
<p><img src="/2020/10/14/opencv/8.png" style="zoom:33%;"></p>
<p><strong>将得到的二值化图像（dst1）利用“非”运算，得到的图像如下：</strong></p>
<p><img src="/2020/10/14/opencv/9.png" style="zoom:33%;"></p>
<p><strong>可以发现，进行“非”运算后，对二值图来说，其实即进行了颜色反转。</strong></p>
</li>
<li></li>
</ul>
<hr>
</li>
</ul>
<h2 id="阈值分割"><a href="#阈值分割" class="headerlink" title="阈值分割"></a>阈值分割</h2><h3 id="固定阈值分割"><a href="#固定阈值分割" class="headerlink" title="固定阈值分割"></a>固定阈值分割</h3><ul>
<li><p><strong>阈值分割简单来说，即大于阈值的变成一种值，小于阈值的为另一种值</strong>   </p>
</li>
<li><p>在python的cv2库中实现固定阈值分割的为<strong>cv2.threshold()函数</strong>。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 <span class="keyword">as</span> cv</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img = cv.imread(<span class="string">r&#x27;D:\Python\image_processing\exercise\imori.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line">ret, th1 = cv.threshold(img, <span class="number">127</span>, <span class="number">255</span>, cv.THRESH_BINARY)</span><br><span class="line">ret,th2=cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_BINARY_INV)</span><br><span class="line">ret,th3=cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TOZERO)</span><br><span class="line">ret,th4=cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TOZERO_INV)</span><br><span class="line">ret,th5=cv.threshold(img,<span class="number">127</span>,<span class="number">255</span>,cv.THRESH_TRUNC)</span><br><span class="line"></span><br><span class="line">titles=[<span class="string">&#x27;Org&#x27;</span>,<span class="string">&#x27;Binary&#x27;</span>,<span class="string">&#x27;Binary_inv&#x27;</span>,<span class="string">&#x27;Tozero&#x27;</span>,<span class="string">&#x27;Tozero_inv&#x27;</span>,<span class="string">&#x27;Trunc&#x27;</span>]</span><br><span class="line">images=[img,th1,th2,th3,th4,th5]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">3</span>,i+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(images[i],<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.title(titles[i],fontsize=<span class="number">16</span>)</span><br><span class="line">    plt.xticks([]),plt.yticks([])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>  运行结果如图所示：</p>
<p>  <img src="/2020/10/14/opencv/1.png" alt="运行结果图" style="zoom:40%;"></p>
<ul>
<li><p><strong>cv2.threshold()函数由4个参数组成，img为传入函数的图像，127为设置的阈值大小(threshold)，255为阈值设定方式里的阈值最大值(maxval)，THRESH_BINARY为阈值设定的方式。</strong>      </p>
</li>
<li><p><strong>ret代表当前的阈值。</strong></p>
</li>
<li><p><strong>matplotlib.pyplot中subplot(2,3,i+1)即为将窗口分为2行3列，i+1表示当前的第i+1个子图，imshow()则是对图像进行处理，它不会让图片进行显示，图像显示需要show()</strong></p>
</li>
<li><p><strong>阈值设定有5种方法，分别为:</strong></p>
<ol>
<li><strong>THRESH_BINARY:</strong></li>
</ol>
<script type="math/tex; mode=display">
dst(x,y)=\begin{cases}
maxval &\ if\ src(x,y)>thresh\\
0 &\ otherwise
\end{cases}</script><p>​        当原像素值大于阈值，原像素值变为maxval，除此之外为0。</p>
<p>​    2.<strong>THRESH_BINARY_INV:</strong></p>
<script type="math/tex; mode=display">
dst(x,y)=\begin{cases}
0 &\ if \ src(x,y)>thresh\\
maxval &\ otherwise
\end{cases}</script><p>​        该阈值方法与上述阈值方法相反，从图像也可以观察得到。</p>
<p>​    3.<strong>THRESH_TOZERO:</strong></p>
<script type="math/tex; mode=display">
dst(x,y)=\begin{cases}
src(x,y) &\ if\ src(x,y)>thresh\\
0 &\ oherwise
\end{cases}</script><p>​        当原像素值大于阈值时，原像素值保持不变，除此之外，原像素值变为0。</p>
<p>​    4.<strong>THRESH_TOZERO_INV:</strong></p>
<script type="math/tex; mode=display">
dst(x,y)=\begin{cases}
0 &\ if \ src(x,y)>thresh\\
src(x,y) &\ otherwise
\end{cases}</script><p>​        该阈值方法与上述阈值方法相反。</p>
<p>​     5.<strong>THRESH_TRUNC:</strong></p>
<script type="math/tex; mode=display">
dst(x,y)=\begin{cases}
threshold &\ if \ src(x,y)>thresh\\
src(x,y) &\ otherwise
\end{cases}</script><p>​        放原像素值大于阈值，则原像素值变为阈值，除此之外，原像素值保持不变。</p>
</li>
</ul>
<h3 id="自适应阈值分割"><a href="#自适应阈值分割" class="headerlink" title="自适应阈值分割"></a>自适应阈值分割</h3><ul>
<li></li>
</ul>
]]></content>
      <tags>
        <tag>图像处理</tag>
      </tags>
  </entry>
</search>
